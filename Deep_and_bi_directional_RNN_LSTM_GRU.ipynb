{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7sKHxEBAFR5M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM, GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the IMDB dataset and unrapping the data\n",
        "\n",
        "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=10000)"
      ],
      "metadata": {
        "id": "7X_D1uXVG-XZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3328abc5-bfcb-4b90-cebd-de30253282ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyIuSBS-CxxU",
        "outputId": "d430bfb0-b4f2-43df-fc52-142ff3371a3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqZwzeaXC7UN",
        "outputId": "eb55049c-7338-47cf-dd72-cf62e3b6ac98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pad_sequences(X_train,maxlen=100)  # Taking max of 100 character legth word sp all word les than 100 will have 0 has starting part and more\n",
        "# 100 character word length will be deleted"
      ],
      "metadata": {
        "id": "RWMuRWM9DC6w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BlJUpFbDVSm",
        "outputId": "a9e2704c-1f23-42d4-b99f-2d022579f2d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1415,   33,    6, ...,   19,  178,   32],\n",
              "       [ 163,   11, 3215, ...,   16,  145,   95],\n",
              "       [1301,    4, 1873, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [  11,    6, 4065, ...,    4, 3586,    2],\n",
              "       [ 100, 2198,    8, ...,   12,    9,   23],\n",
              "       [  78, 1099,   17, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDWLBQl9Db5C",
        "outputId": "4033e80f-ba4b-4f19-d974-3251cc81ee45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1415,   33,    6,   22,   12,  215,   28,   77,   52,    5,   14,\n",
              "        407,   16,   82,    2,    8,    4,  107,  117, 5952,   15,  256,\n",
              "          4,    2,    7, 3766,    5,  723,   36,   71,   43,  530,  476,\n",
              "         26,  400,  317,   46,    7,    4,    2, 1029,   13,  104,   88,\n",
              "          4,  381,   15,  297,   98,   32, 2071,   56,   26,  141,    6,\n",
              "        194, 7486,   18,    4,  226,   22,   21,  134,  476,   26,  480,\n",
              "          5,  144,   30, 5535,   18,   51,   36,   28,  224,   92,   25,\n",
              "        104,    4,  226,   65,   16,   38, 1334,   88,   12,   16,  283,\n",
              "          5,   16, 4472,  113,  103,   32,   15,   16, 5345,   19,  178,\n",
              "         32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[2])  # here every index word will give length 100 as we have taken 100 word length max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6U2IuYEDgGH",
        "outputId": "96ddad0a-3950-4c81-eb0b-96a633498007"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=pad_sequences(X_test,maxlen=100)"
      ],
      "metadata": {
        "id": "fGZhpclXDnOk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test  # Here we can see all words with less than 100 character length will have 0 as starting to make this equal length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qle1dbUkENJz",
        "outputId": "d5efc9f3-b060-4125-ef05-aed2650f5a48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   14,    6,  717],\n",
              "       [   6,  976, 2078, ...,  125,    4, 3077],\n",
              "       [   4, 5673,    7, ...,    9,   57,  975],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   21,  846, 5518],\n",
              "       [   0,    1,   11, ..., 2302,    7,  470],\n",
              "       [  56,   96,  346, ...,   34, 2005, 2643]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelSimpleRNN = Sequential([\n",
        "           Embedding(10000,32,input_length=100), #embedding later to convcer word into vectors, 10000 unique word we are fetching for vector vocubalry\n",
        "                                                 #32 is no. of vector dimention for each word which we want to convert\n",
        "           SimpleRNN(5,return_sequences=True),# RNN layer with five units\n",
        "           SimpleRNN(5),#this is another rnn layer\n",
        "           Dense(1,activation=\"sigmoid\")#outputlayer for the binary claasificaiton\n",
        "])\n"
      ],
      "metadata": {
        "id": "NOJMHW57ERaU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelSimpleRNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcOuxtntFGIg",
        "outputId": "87c6d04e-c823-43a5-ff73-fa4f4fe2424e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100, 5)            190       \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 5)                 55        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320251 (1.22 MB)\n",
            "Trainable params: 320251 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the same deep concept for the LSTM\n",
        "\n",
        "modelLSTM = Sequential([\n",
        "    Embedding(10000,32,input_length=100),\n",
        "    LSTM(5,return_sequences=True),\n",
        "    LSTM(5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "7UjMx7xIHVTW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM.summary()  # LSTM has more parameter as LSTM has 4 hidden layer(forget gate, update gate and output gate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXkzhzsQJ_fW",
        "outputId": "4eb3b2b7-29f7-42f3-bf15-ff3660605891"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 5)            760       \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 5)                 220       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320986 (1.22 MB)\n",
            "Trainable params: 320986 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the same deep concept for the GRU\n",
        "\n",
        "\n",
        "modelGRU = Sequential([\n",
        "    Embedding(10000,32,input_length=100),\n",
        "    GRU(5,return_sequences=True),\n",
        "    GRU(5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "8FldZS34KDgy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRU.summary()  # GRU has less parameteres as compare to LSTM as it has only 2 hidden layer(2 gate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebSSP-lUKksF",
        "outputId": "25bc971d-0701-4e57-8c88-7f8730cb6258"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 100, 5)            585       \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 5)                 180       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320771 (1.22 MB)\n",
            "Trainable params: 320771 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is the use of compilation of model\n",
        "Explanation of the code:\n",
        "This code snippet uses the compile() method to configure several settings for each of the three RNN models (SimpleRNN, LSTM, and GRU) before training them.\n",
        "\n",
        "1. optimizer='adam':\n",
        "\n",
        "This specifies the optimization algorithm used to update the model's weights during training.\n",
        "Adam is a commonly used optimizer for neural networks, known for its efficient and stable performance.\n",
        "2. loss='binary_crossentropy':\n",
        "\n",
        "This defines the loss function used to measure the model's error during training.\n",
        "Binary cross-entropy is a suitable loss function for binary classification tasks like sentiment analysis, where the model predicts a probability between 0 and 1 for each class.\n",
        "3. metrics=['accuracy']:\n",
        "\n",
        "This specifies the metrics used to evaluate the model's performance during training and testing.\n",
        "Accuracy is a commonly used metric for classification tasks, measuring the percentage of correctly classified instances.\n",
        "Why is model compile required for RNN models?\n",
        "Model compilation is a crucial step in any deep learning project, including RNNs. It serves several essential purposes:\n",
        "\n",
        "1. Configuring the training process:\n",
        "\n",
        "Compiling the model defines the optimizer, loss function, and metrics used during training.\n",
        "This allows the model to learn from data and improve its performance.\n",
        "2. Preparing the internal state:\n",
        "\n",
        "RNNs rely on internal states (hidden states) to process sequences of data.\n",
        "Compiling the model initializes these states and ensures they are properly handled during training and prediction.\n",
        "3. Checking for errors:\n",
        "\n",
        "The compilation process can detect certain errors in the model architecture or configuration.\n",
        "This helps identify and fix issues before proceeding with training.\n",
        "4. Optimizing computational efficiency:\n",
        "\n",
        "Compiling the model allows the framework to optimize certain operations for the specific hardware and software environment.\n",
        "This can improve the overall training speed and performance of the model.\n",
        "In summary, compiling an RNN model is essential for configuring the training process, initializing internal states, checking for errors, and optimizing computational efficiency. It ensures the model is properly set up for learning and making accurate predictions on unseen data"
      ],
      "metadata": {
        "id": "f0-lUYdIQirU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile each RNN model\n",
        "modelSimpleRNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "modelLSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "modelGRU.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QDmmPtZpKokw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is avlidation data and test data are same\n",
        "\n",
        "No, validation data and test data are not the same, although they both play important roles in machine learning and deep learning. Here's how they differ:\n",
        "\n",
        "Validation data:\n",
        "\n",
        "Used to fine-tune the model during training.\n",
        "Helps to prevent overfitting by allowing the model to evaluate its performance on data it hasn't seen before.\n",
        "Used to adjust hyperparameters like the learning rate or number of hidden units.\n",
        "Typically not included in the final evaluation of the model's performance.\n",
        "\n",
        "Test data:\n",
        "\n",
        "Used to evaluate the final trained model on unseen data.\n",
        "Provides an unbiased estimate of the model'sgeneralizability to real-world scenarios.\n",
        "Never used to train or fine-tune the model.\n",
        "\n",
        "Key Differences:\n",
        "\n",
        "Feature--Validation data--Test data\n",
        "Purpose--Fine-tuning model,--preventing overfitting--Evaluating model's generalizability\n",
        "Usage--During training--After training\n",
        "Included in final evaluation--No--Yes\n",
        "\n",
        "\n",
        "Analogy:\n",
        "\n",
        "Think of validation data as a dress rehearsal before a play. You use it to practice and make adjustments before the final performance.\n",
        "Think of test data as the actual performance of the play. It shows how well the play goes over with a real audience.\n",
        "\n",
        "In summary:\n",
        "\n",
        "Validation data helps you build a better model.\n",
        "Test data tells you how well your model works in the real world.\n",
        "Both are essential for ensuring your model is reliable and performs well on unseen data."
      ],
      "metadata": {
        "id": "dnZHfWunaIUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "history1 = modelSimpleRNN.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "history2 = modelLSTM.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "history3 = modelGRU.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2k7x47uLa9c",
        "outputId": "dcc9e99a-333f-4b40-fe34-224022901d5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 127s 192ms/step - loss: 0.6815 - accuracy: 0.5518 - val_loss: 0.6551 - val_accuracy: 0.6032\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 96s 153ms/step - loss: 0.5554 - accuracy: 0.7195 - val_loss: 0.5296 - val_accuracy: 0.7442\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 97s 156ms/step - loss: 0.3200 - accuracy: 0.8721 - val_loss: 0.5230 - val_accuracy: 0.7684\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 94s 151ms/step - loss: 0.2059 - accuracy: 0.9264 - val_loss: 0.6569 - val_accuracy: 0.7070\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 96s 153ms/step - loss: 0.1438 - accuracy: 0.9528 - val_loss: 0.6884 - val_accuracy: 0.7448\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 28s 38ms/step - loss: 0.4779 - accuracy: 0.7828 - val_loss: 0.3876 - val_accuracy: 0.8330\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2901 - accuracy: 0.8895 - val_loss: 0.3577 - val_accuracy: 0.8464\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.2081 - accuracy: 0.9266 - val_loss: 0.3890 - val_accuracy: 0.8372\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.1569 - accuracy: 0.9488 - val_loss: 0.4638 - val_accuracy: 0.8310\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.1178 - accuracy: 0.9649 - val_loss: 0.5187 - val_accuracy: 0.8286\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 26s 36ms/step - loss: 0.5145 - accuracy: 0.7401 - val_loss: 0.4122 - val_accuracy: 0.8226\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.3310 - accuracy: 0.8662 - val_loss: 0.3934 - val_accuracy: 0.8288\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.2610 - accuracy: 0.9010 - val_loss: 0.3926 - val_accuracy: 0.8372\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.2119 - accuracy: 0.9244 - val_loss: 0.4176 - val_accuracy: 0.8326\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1722 - accuracy: 0.9409 - val_loss: 0.4382 - val_accuracy: 0.8340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let experiment with test data"
      ],
      "metadata": {
        "id": "gATPDDeuhZJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Vb5lYHfKLX",
        "outputId": "5db6547e-cc6a-4efd-8716-fb200a70b313"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI7Du-gHf_px",
        "outputId": "323c6b95-2b8d-4699-beb5-6cf9fd66e11e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_data = X_test[0][0:100].reshape(1,-1)"
      ],
      "metadata": {
        "id": "JUN4pdi_fO6v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_data = y_test[0][0:100].reshape(1,-1)"
      ],
      "metadata": {
        "id": "FoAt58VzgLlr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAHQH8Azfhks",
        "outputId": "a65354b8-5917-4602-c8af-c704aad172a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelSimpleRNN.predict(X_test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVw6_HQ7a0H4",
        "outputId": "71afd9a8-f038-4b56-c56a-9b50d0a28525"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18255018]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM.predict(X_test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yx87aGkeg1f",
        "outputId": "3076d166-b859-4912-ee53-3122fc648409"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02839947]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRU.predict(X_test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c92tnIYlg6kB",
        "outputId": "1be66b50-6231-4584-99a6-0a1e83d654d7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2695214]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bi-directional RNN and LSTM and GRU"
      ],
      "metadata": {
        "id": "cdBYuF6OhgKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Bidirectional, SimpleRNN, LSTM,GRU,Dense"
      ],
      "metadata": {
        "id": "rYPjrKrlg_na"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK_onCTOhoma",
        "outputId": "b61e1b7f-3adb-436c-efd3-063789af7577"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1415,   33,    6, ...,   19,  178,   32],\n",
              "       [ 163,   11, 3215, ...,   16,  145,   95],\n",
              "       [1301,    4, 1873, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [  11,    6, 4065, ...,    4, 3586,    2],\n",
              "       [ 100, 2198,    8, ...,   12,    9,   23],\n",
              "       [  78, 1099,   17, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRk3eLMHhr6I",
        "outputId": "00d2f03d-5623-4d56-c0ff-35a5be8cf99e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   14,    6,  717],\n",
              "       [   6,  976, 2078, ...,  125,    4, 3077],\n",
              "       [   4, 5673,    7, ...,    9,   57,  975],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   21,  846, 5518],\n",
              "       [   0,    1,   11, ..., 2302,    7,  470],\n",
              "       [  56,   96,  346, ...,   34, 2005, 2643]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen=100\n",
        "embedding_dim=32"
      ],
      "metadata": {
        "id": "IW6UWcmnhvV-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is SimpleRNN model\n",
        "\n",
        "modelSimpleRNN = Sequential([\n",
        "           Embedding(10000,32,input_length=100), #embedding later to convcer word into vectors, 10000 unique word we are fetching for vector vocubalry\n",
        "                                                 #32 is no. of vector dimention for each word which we want to convert\n",
        "           SimpleRNN(5,return_sequences=True),# RNN layer with five units\n",
        "           SimpleRNN(5),#this is another rnn layer\n",
        "           Dense(1,activation=\"sigmoid\")#outputlayer for the binary claasificaiton\n",
        "])"
      ],
      "metadata": {
        "id": "rhGKvk5xh0di"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelSimpleRNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99gTVSHqiH6T",
        "outputId": "4a3459ed-4e36-4115-f5a8-ac32e148d3af"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 100, 5)            190       \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320251 (1.22 MB)\n",
            "Trainable params: 320251 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So by this way we can convert same SimleRNN to bi-directional Simple RNN\n",
        "\n",
        "modelSimpleRNNBidirectional = Sequential([\n",
        "           Embedding(10000,32,input_length=100), #embedding later to convcer word into vectors, 10000 unique word we are fetching for vector vocubalry\n",
        "                                                 #32 is no. of vector dimention for each word which we want to convert\n",
        "           Bidirectional(SimpleRNN(5,return_sequences=True)),# RNN layer with five units by adding bi-directional layer\n",
        "           #SimpleRNN(5),#this is another rnn layer. This will removed\n",
        "           Dense(1,activation=\"sigmoid\")#outputlayer for the binary claasificaiton\n",
        "])"
      ],
      "metadata": {
        "id": "_UzDZYSniLLj"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelSimpleRNNBidirectional.summary()  # In bidirectional total parameter increased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2csjSrqYi1Jv",
        "outputId": "178d0882-5c4d-4782-9137-38421a933a19"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 100, 10)           380       \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100, 1)            11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320391 (1.22 MB)\n",
            "Trainable params: 320391 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTMBidirectional = Sequential([\n",
        "    Embedding(10000,32,input_length=100),\n",
        "    Bidirectional(LSTM(5,return_sequences=True)),\n",
        "    #LSTM(5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "-lzGsbNUjBwy"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTMBidirectional.summary()  # Here in LSTM bidirectional as well paramter increased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cilz7hG1jfBW",
        "outputId": "38b1d8a0-5df7-4956-e9a9-568ea246b498"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 100, 10)           1520      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100, 1)            11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321531 (1.23 MB)\n",
            "Trainable params: 321531 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRUBidirectional = Sequential([\n",
        "    Embedding(10000,32,input_length=100),\n",
        "    Bidirectional(GRU(5,return_sequences=True)),\n",
        "    #GRU(5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "tEMjOYfNjlqB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRUBidirectional.summary()  # same Here as well"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTXm0TO8j8JC",
        "outputId": "ac3561e9-bbbb-4b2d-a951-9c7f20d7cf92"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 100, 10)           1170      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100, 1)            11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321181 (1.23 MB)\n",
            "Trainable params: 321181 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "44RwgJ_ZkA1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}